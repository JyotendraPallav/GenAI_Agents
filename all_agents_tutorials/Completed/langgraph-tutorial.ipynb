{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to LangGraph\n",
    "\n",
    "LangGraph is a framework for creating applications using graph-based workflows. Each node represents a function or computational step, and edges define the flow between these nodes based on certain conditions.\n",
    "\n",
    "## Key Features:\n",
    "- State Management\n",
    "- Flexible Routing\n",
    "- Persistence\n",
    "- Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Overview: Text Analysis Pipeline\n",
    "\n",
    "In this tutorial, we'll demonstrate the power of LangGraph by building a multi-step text analysis pipeline. Our use case will focus on processing a given text through three key stages:\n",
    "\n",
    "1. **Text Classification**: We'll categorize the input text into predefined categories (e.g., News, Blog, Research, or Other).\n",
    "2. **Entity Extraction**: We'll identify and extract key entities such as persons, organizations, and locations from the text.\n",
    "3. **Text Summarization**: Finally, we'll generate a concise summary of the input text.\n",
    "\n",
    "This pipeline showcases how LangGraph can be used to create a modular, extensible workflow for natural language processing tasks. By the end of this tutorial, you'll understand how to construct a graph-based application that can be easily modified or expanded for various text analysis needs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "This cell imports all the necessary modules and classes for our LangGraph tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\A0262\\Downloads\\LearnAgents\\GenAI_Agents\\all_agents_tutorials\\Completed\\Import_LLM.py:14: LangChainDeprecationWarning: The class `AzureChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import AzureChatOpenAI`.\n",
      "  llm = AzureChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import TypedDict, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "from langchain_core.runnables.graph import MermaidDrawMethod\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from Completed.Import_LLM import llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up API Key\n",
    "This cell loads environment variables and sets up the OpenAI API key. Make sure you have a `.env` file with your `OPENAI_API_KEY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# # Set OpenAI API key\n",
    "# os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Text Processing Pipeline\n",
    "\n",
    "### Define State and Initialize LLM\n",
    "Here we define the State class to hold our workflow data and initialize the ChatOpenAI model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    text: str\n",
    "    classification: str\n",
    "    entities: List[str]\n",
    "    summary: str\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Node Functions\n",
    "These functions define the operations performed at each node of our graph: classification, entity extraction, and summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_node(state: State):\n",
    "    ''' Classify the text into one of the categories: News, Blog, Research, or Other '''\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Classify the following text into one of the categories: News, Blog, Research, or Other.\\n\\nText:{text}\\n\\nCategory:\"\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
    "    classification = llm.invoke([message]).content.strip()\n",
    "    return {\"classification\": classification}\n",
    "\n",
    "\n",
    "def entity_extraction_node(state: State):\n",
    "    ''' Extract all the entities (Person, Organization, Location) from the text '''\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Extract all the entities (Person, Organization, Location) from the following text. Provide the result as a comma-separated list.\\n\\nText:{text}\\n\\nEntities:\"\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
    "    entities = llm.invoke([message]).content.strip().split(\", \")\n",
    "    return {\"entities\": entities}\n",
    "\n",
    "\n",
    "def summarization_node(state: State):\n",
    "    ''' Summarize the text in one short sentence '''\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"text\"],\n",
    "        template=\"Summarize the following text in one short sentence.\\n\\nText:{text}\\n\\nSummary:\"\n",
    "    )\n",
    "    message = HumanMessage(content=prompt.format(text=state[\"text\"]))\n",
    "    summary = llm.invoke([message]).content.strip()\n",
    "    return {\"summary\": summary}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tools and Build Workflow\n",
    "This cell builds the StateGraph workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "\n",
    "# Add nodes to the graph\n",
    "workflow.add_node(\"classification_node\", classification_node)\n",
    "workflow.add_node(\"entity_extraction\", entity_extraction_node)\n",
    "workflow.add_node(\"summarization\", summarization_node)\n",
    "\n",
    "# Add edges to the graph\n",
    "workflow.set_entry_point(\"classification_node\") # Set the entry point of the graph\n",
    "workflow.add_edge(\"classification_node\", \"entity_extraction\")\n",
    "workflow.add_edge(\"entity_extraction\", \"summarization\")\n",
    "workflow.add_edge(\"summarization\", END)\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Workflow\n",
    "This cell creates a visual representation of our workflow using Mermaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Display the graph as a Mermaid diagram\n",
    "display(\n",
    "    Image(\n",
    "        app.get_graph().draw_mermaid_png(\n",
    "            draw_method=MermaidDrawMethod.API,\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Pipeline\n",
    "This cell runs a sample text through our pipeline and displays the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification: News\n",
      "\n",
      "Entities: ['OpenAI', 'GPT-4', 'GPT-3']\n",
      "\n",
      "Summary: OpenAI's upcoming GPT-4 model is a multimodal AI designed for improved performance, alignment, and safety, surpassing GPT-3 in efficiency and scalability.\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "OpenAI has announced the GPT-4 model, which is a large multimodal model that exhibits human-level performance on various professional benchmarks. It is developed to improve the alignment and safety of AI systems.\n",
    "additionally, the model is designed to be more efficient and scalable than its predecessor, GPT-3. The GPT-4 model is expected to be released in the coming months and will be available to the public for research and development purposes.\n",
    "\"\"\"\n",
    "\n",
    "state_input = {\"text\": sample_text}\n",
    "result = app.invoke(state_input)\n",
    "\n",
    "print(\"Classification:\", result[\"classification\"])\n",
    "print(\"\\nEntities:\", result[\"entities\"])\n",
    "print(\"\\nSummary:\", result[\"summary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, we've:\n",
    "- Explored LangGraph concepts\n",
    "- Built a text processing pipeline\n",
    "- Demonstrated LangGraph's use in data processing workflows\n",
    "- Visualized the workflow using Mermaid\n",
    "\n",
    "This example showcases how LangGraph can be used for tasks beyond conversational agents, providing a flexible framework for creating complex, graph-based workflows."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AgenticAI2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
